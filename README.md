# ğŸš¨ Real-Time Anomaly Detection System

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.112.0-green.svg)](https://fastapi.tiangolo.com)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

A sophisticated multi-modal AI-powered anomaly detection system that provides real-time monitoring and analysis using computer vision, audio processing, and advanced AI reasoning.

## ğŸŒŸ Features

### ğŸ¯ **Multi-Modal Detection**
- **ğŸƒ Pose Analysis**: Real-time human pose detection using MediaPipe for movement anomalies
- **ğŸ¤ Audio Processing**: Live audio transcription with Whisper AI for verbal indicators
- **ğŸ‘ï¸ Visual Scene Analysis**: CLIP/BLIP models for comprehensive scene understanding
- **ğŸ§  AI Reasoning**: Advanced threat assessment using Groq LLaMA models

### ğŸ”„ **Real-Time Processing**
- **ğŸ“¡ WebSocket Streaming**: Live video feed with 1 FPS anomaly detection
- **ğŸ“¹ Video Recording**: Continuous MP4 recording with anomaly frame capture
- **âš¡ Live Dashboard**: Web-based monitoring interface with JSON output
- **ğŸ–¼ï¸ Frame Saving**: Automatic anomaly frame extraction and storage

### ğŸ›ï¸ **Advanced Analysis**
- **ğŸ”— Multi-Modal Fusion**: Intelligent correlation of pose, audio, and visual data
- **ğŸ“Š Threat Scoring**: Comprehensive threat severity assessment (0-1 scale)
- **ğŸ¯ Anomaly Classification**: Detection of falls, aggression, medical emergencies
- **ğŸ“ˆ Confidence Assessment**: AI-powered uncertainty quantification

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Live Camera   â”‚    â”‚   Audio Stream  â”‚    â”‚  Web Dashboard  â”‚
â”‚    Feed (CV2)   â”‚    â”‚   (PyAudio)     â”‚    â”‚   (FastAPI)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚                      â”‚
          â–¼                      â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     TIER 1 PIPELINE                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Pose      â”‚  â”‚   Audio     â”‚  â”‚    Scene Analysis       â”‚ â”‚
â”‚  â”‚ Processing  â”‚  â”‚ Processing  â”‚  â”‚   (CLIP/BLIP Models)    â”‚ â”‚
â”‚  â”‚ (MediaPipe) â”‚  â”‚ (Whisper)   â”‚  â”‚                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                            â”‚                                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                    â”‚ Fusion Logic  â”‚                          â”‚
â”‚                    â”‚  (Threshold)  â”‚                          â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚         Anomaly Detected?     â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ YES
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     TIER 2 PIPELINE                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Enhanced    â”‚  â”‚ Large Model â”‚  â”‚   Advanced Scene        â”‚ â”‚
â”‚  â”‚ Audio       â”‚  â”‚ Transcript  â”‚  â”‚   Captioning            â”‚ â”‚
â”‚  â”‚ Analysis    â”‚  â”‚ (Whisper)   â”‚  â”‚   (BLIP Model)          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                            â”‚                                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                    â”‚  AI Reasoning â”‚                          â”‚
â”‚                    â”‚ (Groq LLaMA)  â”‚                          â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ Detailed Report â”‚
                â”‚ + Threat Score  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### ğŸ“‹ Prerequisites

- **Python 3.10+**
- **Camera/Webcam** for video input
- **Microphone** for audio input
- **GROQ API Key** (free at [console.groq.com](https://console.groq.com))

### ğŸ› ï¸ Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/anomaly-detection.git
cd anomaly-detection
```

2. **Set up Python environment**
```bash
# Using pyenv (recommended)
pyenv install 3.10.11
pyenv local 3.10.11
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Or using conda
conda create -n anomaly-detection python=3.10
conda activate anomaly-detection
```

3. **Install dependencies**
```bash
cd backend
pip install -r requirements.txt
```

4. **Download required models**
```bash
# MediaPipe Pose Model (should auto-download)
# Whisper models will download automatically on first use
# CLIP/BLIP models will download from HuggingFace automatically
```

5. **Set up environment variables**
```bash
# Create .env file in backend directory
cp .env.example .env

# Add your GROQ API key
echo "GROQ_API_KEY=your_groq_api_key_here" > .env
```

### ğŸƒ Running the System

1. **Start the server**
```bash
cd backend
python -m uvicorn app:app --reload --host 127.0.0.1 --port 8000
```

2. **Open the dashboard**
Navigate to: `http://localhost:8000/dashboard.html`

3. **Monitor in real-time**
- View live video stream with anomaly overlays
- Monitor JSON output for detailed analysis
- Check saved anomaly frames and videos

## ğŸ“ Project Structure

```
anomaly-detection/
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â””â”€â”€ backend/
    â”œâ”€â”€ app.py                 # Main FastAPI application
    â”œâ”€â”€ dashboard.html         # Web monitoring interface
    â”œâ”€â”€ requirements.txt       # Python dependencies
    â”œâ”€â”€ .env                   # Environment variables
    â”œâ”€â”€ pose_landmarker_heavy.task  # MediaPipe model
    â”œâ”€â”€ tier1/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ tier1_pipeline.py  # Real-time anomaly detection
    â”œâ”€â”€ tier2/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ tier2_pipeline.py  # Advanced AI analysis
    â”œâ”€â”€ utils/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ audio_processing.py    # Whisper audio transcription
    â”‚   â”œâ”€â”€ pose_processing.py     # MediaPipe pose analysis
    â”‚   â”œâ”€â”€ scene_processing.py    # CLIP/BLIP visual analysis
    â”‚   â””â”€â”€ fusion_logic.py        # Multi-modal fusion & AI reasoning
    â”œâ”€â”€ anomaly_frames/        # Saved anomaly images
    â””â”€â”€ recorded_videos/       # Recorded video sessions
```

## ğŸ”§ Configuration

### ğŸšï¸ Detection Sensitivity

Adjust thresholds in `utils/fusion_logic.py`:

```python
# Tier 1 Thresholds
scene_threshold = 0.20      # Scene anomaly sensitivity (0.0-1.0)
pose_threshold = 0.15       # Pose movement sensitivity
cooldown_ms = 1000          # Anomaly detection cooldown

# Scene Processing Threshold
anomaly_threshold = 0.8     # CLIP model sensitivity multiplier
```

### ğŸ¬ Pose Detection

Modify sensitivity in `utils/pose_processing.py`:

```python
# Movement Thresholds
wrist_speed_threshold = 0.15    # Rapid arm movements
head_movement_threshold = 0.08  # Head position changes
torso_change_threshold = 0.05   # Bending/postural changes
```

### ğŸ”Š Audio Processing

Configure in `utils/audio_processing.py`:

```python
# Audio Settings
sample_rate = 16000         # Whisper-compatible rate
buffer_size = 32            # ~2 second audio buffer
chunk_size = 1024           # Audio chunk size
```

## ğŸ“Š API Endpoints

### ğŸŒ Web Interface
- `GET /dashboard.html` - Main monitoring dashboard
- `GET /video_stream` - Live video stream with overlays

### ğŸ“¡ WebSocket
- `WS /stream_video` - Real-time anomaly detection stream

### ğŸ“‹ REST API
- `GET /anomaly_events` - Latest anomaly detections
- `GET /anomaly_frames/{filename}` - Anomaly frame images
- `GET /recorded_videos/{filename}` - Recorded video files

## ğŸ§ª Example Output

### ğŸ“„ Tier 1 Detection
```json
{
  "status": "Suspected Anomaly",
  "details": "Pose anomaly: True, Scene probability: 0.26",
  "frame_count": 2850,
  "timestamp": 95.0,
  "tier1_components": {
    "pose_analysis": {
      "anomaly_detected": true,
      "summary": "Pose anomaly detected: True"
    },
    "audio_analysis": {
      "transcripts": ["Help me!", "Something's wrong"],
      "transcript_text": "Help me! | Something's wrong"
    },
    "scene_analysis": {
      "anomaly_probability": 0.26,
      "summary": "Scene anomaly probability: 0.26"
    }
  }
}
```

### ğŸ§  Tier 2 Analysis
```json
{
  "visual_score": 0.75,
  "audio_score": 0.85,
  "text_alignment_score": 0.80,
  "multimodal_agreement": 0.78,
  "reasoning_summary": "The pose anomaly suggests unusual body position potentially indicating distress. Audio transcript contains explicit calls for help suggesting genuine emergency. Visual scene shows person in compromised position. All modalities strongly correlate indicating high-confidence genuine anomaly requiring immediate attention.",
  "threat_severity_index": 0.85,
  "tier2_components": {
    "audio_analysis": {
      "full_transcript": "Help me! Something's wrong, I need assistance!",
      "available": true,
      "length": 45
    },
    "visual_analysis": {
      "captions": ["person on ground reaching for help"],
      "visual_anomaly_score": 0.75,
      "description": "person on ground reaching for help"
    }
  }
}
```

## ğŸ¤– AI Models Used

### ğŸƒ Pose Detection
- **MediaPipe Pose Landmarker Heavy** - 33-point skeletal tracking
- **Real-time processing** at 30 FPS with 1 FPS anomaly analysis

### ğŸ¤ Audio Processing
- **OpenAI Whisper Tiny** - Fast transcription for Tier 1
- **OpenAI Whisper Large** - Accurate transcription for Tier 2

### ğŸ‘ï¸ Visual Analysis
- **CLIP ViT-Base-Patch32** - Scene classification and anomaly detection
- **CLIP ViT-Large-Patch14** - Enhanced analysis for Tier 2
- **BLIP Image Captioning** - Detailed scene descriptions

### ğŸ§  AI Reasoning
- **Groq LLaMA 3 8B** - Fast inference for real-time analysis
- **Groq LLaMA 3 70B** - Detailed reasoning for complex cases

## ğŸ” Anomaly Types Detected

### ğŸš¨ Physical Anomalies
- **Falls and collapses**
- **Aggressive movements** (punching, fighting)
- **Medical emergencies** (seizures, distress)
- **Unusual postures** (crawling, crouching)

### ğŸ—£ï¸ Audio Anomalies
- **Distress calls** ("Help!", "Emergency!")
- **Aggressive language** (threats, shouting)
- **Medical indicators** (pain expressions, confusion)
- **Abnormal speech patterns**

### ğŸ¬ Visual Anomalies
- **Environmental hazards**
- **Weapon detection**
- **Unusual object placement**
- **Scene context changes**

## ğŸ›¡ï¸ Security & Privacy

- **Local Processing** - All AI inference runs locally
- **No Cloud Storage** - Videos and frames stored locally only
- **API Key Security** - GROQ API key stored in environment variables
- **Data Retention** - Configurable retention policies for recordings

## ğŸš€ Performance

### âš¡ Real-Time Metrics
- **Video Processing**: 30 FPS capture, 1 FPS analysis
- **Audio Processing**: 2-second rolling buffer
- **Detection Latency**: < 2 seconds end-to-end
- **Memory Usage**: ~2-4GB depending on models loaded

### ğŸ–¥ï¸ System Requirements
- **CPU**: Multi-core processor (Intel i5+ or AMD equivalent)
- **RAM**: 8GB minimum, 16GB recommended
- **GPU**: Optional (CUDA support for faster inference)
- **Storage**: 10GB free space for models and recordings

## ğŸ¤ Contributing

1. **Fork the repository**
2. **Create a feature branch** (`git checkout -b feature/amazing-feature`)
3. **Commit your changes** (`git commit -m 'Add amazing feature'`)
4. **Push to the branch** (`git push origin feature/amazing-feature`)
5. **Open a Pull Request**

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **MediaPipe** team for pose detection models
- **OpenAI** for Whisper audio processing
- **Hugging Face** for CLIP/BLIP vision models
- **Groq** for fast LLaMA inference
- **FastAPI** for the web framework

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/anomaly-detection/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/anomaly-detection/discussions)
- **Email**: your.email@example.com

---

<div align="center">
  <strong>Built with â¤ï¸ using Python, AI, and Computer Vision</strong>
</div>
